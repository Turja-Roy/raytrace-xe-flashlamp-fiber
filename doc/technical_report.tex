\input{preamble.tex}
\usepackage{bm}

\title{\large\bfseries
    Optimization of Two-Lens Coupling Systems for VUV Flashlamp to Fiber Applications Using Ray Tracing and Multi-Algorithm Comparison
}

\author{Turja Roy}
\affil{Department of Physics, University of Texas at Arlington}
\date{}

\begin{document}

\twocolumn[
\begin{@twocolumnfalse}
    \maketitle

    \begin{abstract}
        A comprehensive ray tracing methodology is presented for optimizing two-lens plano-convex optical systems designed to couple vacuum ultraviolet (VUV) light from xenon flashlamp sources into optical fibers. Operating at 200 nm wavelength, the system addresses the challenge of efficiently collecting light from a 3 mm diameter arc source with a 33° divergence angle and coupling it into a 1 mm core fiber with 0.22 numerical aperture. A Monte Carlo ray tracing approach incorporating full geometric optics and atmospheric absorption is employed to evaluate coupling efficiency. Six optimization algorithms—grid search, Powell's method, differential evolution, Nelder-Mead simplex, dual annealing, and Bayesian optimization—are implemented in a modular framework and systematically compared. Atmospheric O$_2$ absorption at 200 nm is modeled using the Minschwaner parameterization, revealing $\sim$11\% coupling reduction compared to vacuum propagation. Results demonstrate coupling efficiencies ranging from 0.19 to 0.24 for optimized configurations in air, with system lengths between 33 and 95 mm depending on lens selection. Differential evolution emerges as the most effective method, achieving 10--56$\times$ faster convergence than grid search while finding superior solutions. Comparison of air and argon propagation media shows negligible performance difference, validating air as a practical working environment. The multi-objective optimization framework successfully balances coupling efficiency and system compactness through a tunable weighted objective function. This work provides both a practical computational tool for VUV fiber coupling design and methodological insights into optimization strategy selection for non-convex optical design problems.
    \end{abstract}
    \vspace{0.5cm}
\end{@twocolumnfalse}
]

\section{Introduction}

Efficient coupling of vacuum ultraviolet light from incoherent sources into optical fibers presents significant challenges due to the inherent divergence of arc lamp sources and the limited acceptance angles of fibers \cite{hecht2017}. Xenon flashlamps operating in the VUV regime (200 nm) are widely used in applications including spectroscopy, photochemistry, and materials characterization, where fiber-optic delivery enables flexible and remote illumination.

The design of compact coupling optics requires balancing multiple objectives: maximizing coupling efficiency, minimizing physical length, and maintaining practical manufacturability with commercially available optical components. Traditional lens design approaches often rely on paraxial approximations or specialized optical design software \cite{greivenkamp2004}. However, the large numerical aperture and wide divergence angles in VUV flashlamp systems necessitate full ray tracing to accurately predict system performance.

In this work, a Monte Carlo ray tracing framework is developed that incorporates realistic source geometry, lens specifications, and fiber acceptance criteria. The design problem is formulated as a multi-objective optimization task, and six distinct optimization algorithms are systematically compared to identify lens positioning that maximizes performance. This approach provides both a practical design tool and insights into the efficacy of various optimization strategies for optical systems with complex, non-convex objective functions.

\section{System Description}

\subsection{Optical Configuration}

The optical system comprises a xenon arc lamp \cite{hamamatsu}, a protective window, two fused silica plano-convex lenses, and a multi-mode optical fiber \cite{accuglass} arranged along a common optical axis (Fig. 1, not shown). The arc lamp emits VUV radiation at $\lambda = 200$ nm with a compact 3.0 mm diameter arc. A fused silica window (14.3 mm diameter) positioned 8.7 mm from the arc protects the source while allowing VUV transmission. The two-lens relay system is positioned after the window to collect and refocus the divergent light into the fiber.

\subsection{Source Characteristics}

The xenon arc source exhibits a spatially extended emission profile with angular divergence that increases radially from the arc center. The source is modeled as emitting rays from a circular disk of radius $r_{\text{arc}} = 1.5$ mm with angular distribution characterized by a maximum half-angle $\theta_{\max} = 33^\circ$ at the window edge. This coherent beam model assumes that rays originating at radius $r$ from the arc center propagate with half-angle $\theta(r) = \theta_{\max} \cdot r/r_{\text{arc}}$, representing the geometric constraint imposed by the window aperture.

\subsection{Fiber Specifications}

The target optical fiber features a 1.0 mm core diameter with numerical aperture NA $= 0.22$, corresponding to an acceptance half-angle $\theta_{\text{accept}} = \sin^{-1}(\text{NA}) = 12.4^\circ$ in air. Successful coupling requires that incident rays satisfy both spatial (impinge within the core area) and angular (arrive within the acceptance cone) criteria simultaneously.

\subsection{Lens Properties}

All lenses are fabricated from UV-grade fused silica with refractive index $n = 1.578$ at 200 nm, calculated using the Sellmeier dispersion formula \cite{malitson1965}. Plano-convex geometry is selected for its favorable aberration characteristics and commercial availability. Lenses are oriented with the curved surface facing the source to minimize spherical aberration. Specifications including focal length $f$, radius of curvature $R$, center thickness $t_c$, edge thickness $t_e$, and clear aperture diameter are drawn from manufacturer catalogs \cite{thorlabs,edmundoptics}.

\section{Computational Methods}

\subsection{Monte Carlo Ray Sampling}

A Monte Carlo approach is employed to statistically sample the phase space of rays emitted by the extended source. For each simulation, $N = 1000$ to 2000 rays are generated with origins uniformly distributed over the arc area and directions following the prescribed angular distribution.

Radial positions are sampled using inverse transform sampling to ensure uniform spatial distribution:
\begin{align}
r_i &= \sqrt{U_i} \cdot r_{\text{arc}}, \quad U_i \sim \mathcal{U}(0,1) \\
\phi_i &= \frac{2\pi i}{N}
\end{align}
where $\mathcal{U}(0,1)$ denotes the uniform distribution. Azimuthal angles $\phi_i$ are uniformly spaced to provide comprehensive angular coverage. The Cartesian coordinates of source points are:
\begin{equation}
\mathbf{o}_i = (r_i \cos\phi_i, \, r_i \sin\phi_i, \, 0)
\end{equation}

The ray propagation half-angle scales linearly with radial position:
\begin{equation}
\theta_i = \theta_{\max} \cdot \frac{r_i}{r_{\text{arc}}}
\end{equation}
resulting in direction vectors:
\begin{equation}
\mathbf{d}_i = (\sin\theta_i \cos\phi_i, \, \sin\theta_i \sin\phi_i, \, \cos\theta_i)
\end{equation}
All direction vectors are normalized to unit length.

\subsection{Geometric Ray Tracing}

Ray propagation through the optical system is computed using vector-based geometric optics without paraxial approximations \cite{glassner1989}. This approach accurately accounts for large ray angles, finite apertures, and aberrations.

\subsubsection{Ray-Surface Intersection}

For a spherical surface of radius $R$ centered at $\mathbf{c}$, the intersection of ray $\mathbf{p}(t) = \mathbf{o} + t\mathbf{d}$ is found by solving:
\begin{equation}
\|\mathbf{o} + t\mathbf{d} - \mathbf{c}\|^2 = R^2
\end{equation}
Expanding yields the quadratic equation:
\begin{align}
a &= 1 \\
b &= 2(\mathbf{o} - \mathbf{c}) \cdot \mathbf{d} \\
c &= \|\mathbf{o} - \mathbf{c}\|^2 - R^2 \\
\Delta &= b^2 - 4c
\end{align}
The nearest positive intersection occurs at:
\begin{equation}
t = \frac{-b - \sqrt{\Delta}}{2}, \quad \Delta \geq 0
\end{equation}
Rays missing the surface ($\Delta < 0$) or blocked by the aperture ($\sqrt{p_x^2 + p_y^2} > r_{\text{ap}}$) are rejected.

\subsubsection{Vector Refraction}

At each refractive interface, Snell's law is applied in vector form. For incident ray $\mathbf{d}_{\text{in}}$, surface normal $\mathbf{n}$ (pointing into the incident medium), and refractive indices $n_1$ and $n_2$:
\begin{align}
\eta &= \frac{n_1}{n_2} \\
\cos\theta_i &= -\mathbf{n} \cdot \mathbf{d}_{\text{in}} \\
k &= 1 - \eta^2(1 - \cos^2\theta_i)
\end{align}
Total internal reflection occurs when $k < 0$. Otherwise, the refracted ray is:
\begin{equation}
\mathbf{d}_{\text{out}} = \eta \mathbf{d}_{\text{in}} + (\eta \cos\theta_i - \sqrt{k})\mathbf{n}
\end{equation}
For the spherical front surface, the outward normal is $\mathbf{n} = (\mathbf{p} - \mathbf{c})/R$. For the planar back surface, $\mathbf{n} = (0, 0, -1)$.

\subsubsection{Lens Propagation}

Within each lens, the ray propagates a distance determined by the local lens thickness. For a plano-convex lens with center thickness $t_c$ and edge thickness $t_e$, the thickness at radial position $r$ is:
\begin{equation}
t_{\text{local}}(r) = t_c - (t_c - t_e) \cdot \frac{r}{r_{\text{ap}}}
\end{equation}
The exit point on the back surface is:
\begin{equation}
\mathbf{o}_{\text{back}} = \mathbf{p}_{\text{front}} + \frac{t_{\text{local}}}{|d_z|} \mathbf{d}_{\text{refracted}}
\end{equation}

\subsection{Fiber Coupling Analysis}

After traversing both lenses, rays propagate to the fiber face located at $z = z_{\text{fiber}}$. The intersection point is computed as:
\begin{equation}
\mathbf{p}_{\text{fiber}} = \mathbf{o}_2 + \frac{z_{\text{fiber}} - o_{2z}}{d_{2z}} \mathbf{d}_2
\end{equation}
where $\mathbf{o}_2$ and $\mathbf{d}_2$ are the ray origin and direction after the second lens.

A ray successfully couples into the fiber if:
\begin{enumerate}[leftmargin=*]
    \item \textit{Spatial criterion}: $\sqrt{p_x^2 + p_y^2} \leq r_{\text{core}} = 0.5$ mm
    \item \textit{Angular criterion}: $\theta = \arccos(|d_{2z}|/\|\mathbf{d}_2\|) \leq \theta_{\text{accept}} = 12.4^\circ$
\end{enumerate}
The coupling efficiency is:
\begin{equation}
\eta_{\text{coupling}} = \frac{N_{\text{accepted}}}{N_{\text{total}}}
\end{equation}

\section{Optimization Framework}

\subsection{Problem Formulation}

The optical design task is formulated as a constrained multi-objective optimization problem. Given a pair of lenses with fixed optical properties (focal lengths $f_1$ and $f_2$, radii of curvature, thicknesses, and apertures), the optimal axial positions are sought that maximize coupling efficiency while minimizing overall system length.

\subsubsection{Design Variables}

The optimization space comprises three continuous parameters:
\begin{itemize}[leftmargin=*]
    \item $z_1$: axial position of the first lens vertex (mm)
    \item $z_2$: axial position of the second lens vertex (mm)  
    \item $z_{\text{fiber}}$: axial position of the fiber face (mm)
\end{itemize}

Physical constraints ensure feasible configurations:
\begin{align}
z_1 &\geq z_{\text{window}} + \Delta z_{\text{min}} = 9.7\text{ mm} \\
z_2 &> z_1 + 0.1\text{ mm} \\
z_{\text{fiber}} &\approx z_2 + f_2
\end{align}
where the fiber position is typically placed one focal length beyond the second lens as a starting approximation.

\subsubsection{Objective Function}

A weighted-sum scalarization is employed to combine coupling efficiency maximization and length minimization:
\begin{equation}
\min_{z_1,z_2} f(z_1, z_2) = \alpha(1 - \eta_{\text{coupling}}) + (1-\alpha)\frac{z_{\text{fiber}}}{L_{\text{norm}}}
\end{equation}
where $\alpha \in [0,1]$ is the preference weight (default $\alpha = 0.7$ prioritizes coupling), and $L_{\text{norm}} = 80$ mm is a normalization length. This formulation converts both objectives to minimization with comparable scales.

Each evaluation of $f(z_1, z_2)$ requires complete ray tracing of $N$ rays through the system, making the objective function computationally expensive and non-differentiable due to discrete ray counting and aperture clipping.

\subsection{Optimization Algorithms}

Six optimization methods are implemented and compared, representing different algorithmic paradigms: exhaustive search, local gradient-free methods, and global stochastic approaches.

\subsubsection{Grid Search}

An exhaustive two-stage search, implemented from scratch, establishes a performance baseline. In the coarse stage, a $7 \times 7$ grid samples the parameter space with bounds determined by lens focal lengths:
\begin{align}
z_1 &\in [9.7, \, \max(14.7, 1.5f_1)] \\
z_2 &\in [z_1 + 0.5f_2, \, z_1 + 2.5f_2]
\end{align}
The best coarse solution undergoes local refinement via a $9 \times 9$ grid spanning $\pm 2\Delta$ around the coarse optimum, where $\Delta$ is the coarse grid spacing. Total evaluations: 130 per lens pair.

Implementation: \texttt{scripts/optimization/grid\_search.py}. Uses 500 rays per evaluation to balance accuracy and speed. Fiber position is fixed at $z_{\text{fiber}} = z_2 + f_2$ for each $(z_1, z_2)$ pair.

\subsubsection{Powell's Method}

Powell's conjugate direction method \cite{powell1964} performs derivative-free local optimization by iteratively minimizing along coordinate axes and constructed conjugate directions. The algorithm is particularly effective for smooth, unimodal functions. 

Implementation uses SciPy's \texttt{optimize.minimize} with method \texttt{'Powell'} \cite{scipy}. Parameters: 200 maximum iterations, position tolerance $\Delta x = 0.01$ mm, function tolerance $\Delta f = 0.001$. Initial guess: $z_1^{(0)} = \max(9.7, 0.8f_1)$, $z_2^{(0)} = z_1^{(0)} + 1.2f_2$. Uses 1000 rays per evaluation for higher precision than grid search.

Module: \texttt{scripts/optimization/powell.py}. Typically converges in 30--50 function evaluations.

\subsubsection{Nelder-Mead Simplex}

The Nelder-Mead algorithm \cite{nelder1965} maintains a simplex of $n+1$ points in $n$-dimensional space, updating via geometric transformations (reflection, expansion, contraction, shrinkage). It is robust to function noise and requires no derivatives.

Implementation uses SciPy's \texttt{optimize.minimize} with method \texttt{'Nelder-Mead'} \cite{scipy}. Parameters: 200 maximum iterations, position tolerance 0.01 mm, function tolerance 0.001. Same initialization as Powell's method. Uses 1000 rays per evaluation.

Module: \texttt{scripts/optimization/nelder\_mead.py}. Fastest local method, typically converging in 20--40 evaluations.

\subsubsection{Differential Evolution}

Differential evolution \cite{storn1997} is a population-based global optimizer using evolutionary strategies. At each generation, trial vectors are created via:
\begin{equation}
\mathbf{x}_{\text{trial}} = \mathbf{x}_r + F(\mathbf{x}_a - \mathbf{x}_b)
\end{equation}
where $\mathbf{x}_r$, $\mathbf{x}_a$, $\mathbf{x}_b$ are randomly selected population members and $F$ is the mutation factor. Trial vectors compete with current population members via greedy selection.

Implementation uses SciPy's \texttt{optimize.}\allowbreak\texttt{differential\_evolution} \cite{scipy}. Parameters: population size 10, maximum 50 iterations, tolerance 0.001. Bounds as specified for grid search. Uses 1000 rays per evaluation.

Module: \texttt{scripts/optimization/differential\_evolution.py}. \textbf{Recommended default method} due to superior balance of speed and solution quality. Typical evaluations: 60--100.

\subsubsection{Dual Annealing}

Dual annealing \cite{xiang2013,xiang2000} combines classical simulated annealing with local search to escape local minima. The algorithm accepts worse solutions probabilistically according to the Boltzmann criterion:
\begin{equation}
P_{\text{accept}} = \exp\left(-\frac{\Delta f}{k_B T}\right)
\end{equation}
where $T$ decreases according to an adaptive cooling schedule.

Implementation uses SciPy's \texttt{optimize.}\allowbreak\texttt{dual\_annealing} \cite{scipy}. Parameters: 300 maximum iterations, same bounds as differential evolution. Uses 1000 rays per evaluation. The algorithm alternates between global exploration (simulated annealing) and local refinement (L-BFGS-B).

Module: \texttt{scripts/optimization/dual\_annealing.py}. Effective for highly multi-modal landscapes. Typical evaluations: 80--120.

\subsubsection{Bayesian Optimization}

Bayesian optimization \cite{mockus1978,jones1998} builds a Gaussian process (GP) surrogate model of the objective function and selects evaluation points by maximizing an acquisition function, typically expected improvement (EI):
\begin{equation}
\text{EI}(\mathbf{x}) = \mathbb{E}[\max(f_{\text{best}} - f(\mathbf{x}), 0)]
\end{equation}
This approach is sample-efficient, making it suitable for expensive objectives. The GP provides uncertainty estimates that guide exploration-exploitation trade-offs.

Implementation uses scikit-optimize's \texttt{gp\_minimize} \cite{skopt}. Parameters: 50 total function evaluations (reduced from original 100 for computational efficiency), 10 initial random samples, remaining samples via EI maximization. Uses 1000 rays per evaluation. Requires additional package: \texttt{pip install scikit-optimize}.

Module: \texttt{scripts/optimization/bayesian.py}. Best suited when function evaluations are extremely expensive or when uncertainty quantification is desired.

\section{Material Properties}

The refractive index of fused silica at VUV wavelengths is calculated using the Sellmeier dispersion equation \cite{malitson1965}:
\begin{equation}
n^2(\lambda) = 1 + \sum_{i=1}^{3} \frac{B_i\lambda^2}{\lambda^2 - C_i}
\end{equation}
with Malitson coefficients:
\begin{align*}
B_1 &= 0.6961663, \quad C_1 = (0.0684043)^2 \\
B_2 &= 0.4079426, \quad C_2 = (0.1162414)^2 \\
B_3 &= 0.8974794, \quad C_3 = (9.896161)^2
\end{align*}
where wavelength $\lambda$ is expressed in micrometers. At the operating wavelength $\lambda = 0.2$ $\mu$m (200 nm), this yields $n = 1.578$.

\section{Atmospheric Attenuation}

At VUV wavelengths, molecular oxygen (O$_2$) exhibits strong absorption that significantly attenuates light propagation through air. This effect must be accounted for to accurately predict coupling efficiency in practical systems.

\subsection{Beer-Lambert Absorption}

The transmission of light through an absorbing medium follows the Beer-Lambert law:
\begin{equation}
T = \exp(-\alpha d)
\end{equation}
where $T$ is the fractional transmission, $\alpha$ is the wavelength-dependent attenuation coefficient (mm$^{-1}$), and $d$ is the propagation distance (mm).

The attenuation coefficient for a multi-component gas mixture is:
\begin{equation}
\alpha(\lambda) = \sum_i \sigma_i(\lambda) n_i
\end{equation}
where $\sigma_i(\lambda)$ is the absorption cross-section (cm$^2$) of species $i$ and $n_i$ is its number density (molecules/cm$^3$).

\subsection{O$_2$ Absorption Cross-Section}

At 200 nm, oxygen absorption dominates atmospheric attenuation. The cross-section is computed using the Minschwaner parameterization \cite{minschwaner1992}, valid for 175--242 nm:
\begin{equation}
\log_{10} \sigma_{\text{O}_2}(\lambda) = a_0 + a_1\lambda + a_2\lambda^2 + a_3\lambda^3 + a_4\lambda^4 + a_5\lambda^5 - 16
\end{equation}
with coefficients:
\begin{align*}
a_0 &= -4.4011 \times 10^1, \quad a_1 = 6.2067 \times 10^{-1} \\
a_2 &= -3.5668 \times 10^{-3}, \quad a_3 = 9.5745 \times 10^{-6} \\
a_4 &= -1.2775 \times 10^{-8}, \quad a_5 = 6.6574 \times 10^{-12}
\end{align*}
where $\lambda$ is in nanometers and $\sigma$ is in cm$^2$. At 200 nm, this yields $\sigma_{\text{O}_2} = 1.15 \times 10^{-20}$ cm$^2$.

\subsection{Number Density Calculation}

Number densities are computed from the ideal gas law:
\begin{equation}
n = \frac{P}{k_B T}
\end{equation}
where $P$ is pressure, $T$ is temperature, and $k_B = 1.381 \times 10^{-23}$ J/K is Boltzmann's constant. At standard conditions ($P = 1$ atm, $T = 293$ K), the total number density is $n_{\text{total}} = 2.50 \times 10^{19}$ molecules/cm$^3$.

For dry air composition:
\begin{align}
n_{\text{O}_2} &= 0.21 \times n_{\text{total}} = 5.25 \times 10^{18} \text{ cm}^{-3} \\
n_{\text{N}_2} &= 0.78 \times n_{\text{total}} = 1.95 \times 10^{19} \text{ cm}^{-3}
\end{align}
N$_2$ absorption is negligible above 100 nm. Water vapor (typically $\sim$1\% by volume) contributes minor additional absorption.

\subsection{Attenuation Implementation}

The attenuation coefficient for air at 200 nm is:
\begin{equation}
\alpha_{\text{air}} = \sigma_{\text{O}_2} n_{\text{O}_2} \approx 0.060 \text{ mm}^{-1}
\end{equation}

Each ray's intensity is attenuated according to its cumulative path length $d_{\text{total}}$ through air:
\begin{equation}
I_{\text{fiber}} = I_0 \exp(-\alpha_{\text{air}} d_{\text{total}})
\end{equation}
where $d_{\text{total}}$ includes propagation from arc to window, inter-lens distances, and lens-to-fiber distance. For typical system lengths of 30--100 mm, transmission ranges from 16\% to 0.25\%, representing substantial loss.

This absorption model is implemented in \texttt{scripts/calcs.py} using cross-section data from \texttt{scripts/hitran\_data.py}.

\section{Model Assumptions and Validity}

The ray tracing model incorporates several simplifying assumptions:

\begin{enumerate}[leftmargin=*]
    \item \textit{Geometric optics regime}: The wavelength ($\lambda = 200$ nm) is negligible compared to all physical dimensions (apertures $\sim$ 1-25 mm), validating the ray approximation and neglecting diffraction effects.
    
    \item \textit{Coherent source model}: The angular distribution is deterministic with respect to radial position. Real arc lamps exhibit additional angular spread; this model represents an idealized geometric limit.
    
    \item \textit{Perfect optical surfaces}: Surface roughness, figure errors, and manufacturing imperfections are neglected. Real VUV optics may deviate from ideal spherical and planar surfaces.
    
    \item \textit{Atmospheric absorption included; surface losses neglected}: Molecular absorption (primarily O$_2$ at 200 nm) is modeled using the Beer-Lambert law with Minschwaner cross-sections. However, Fresnel reflections at each air-glass interface (approximately 4-5\% per surface at 200 nm, totaling $\sim$20\% for 4 surfaces) and bulk absorption in fused silica are not included. Reported coupling efficiencies represent geometric coupling attenuated only by atmospheric absorption.
    
    \item \textit{Monochromatic light}: Chromatic aberration is absent. Real flashlamp spectra span broad wavelength ranges.
    
    \item \textit{Perfect alignment}: Lens decentration, tilt, and fiber misalignment errors are assumed zero. Practical systems require careful alignment procedures.
    
    \item \textit{Uniform fiber acceptance}: The numerical aperture is assumed constant across the core. Variations due to fiber manufacturing tolerances are ignored.
\end{enumerate}

These assumptions are appropriate for design-stage performance prediction. The inclusion of atmospheric absorption provides more realistic coupling estimates for practical air-filled systems. Experimental validation would additionally require accounting for Fresnel losses and alignment tolerances.

\section{Results}

\subsection{Implementation Architecture}

The optimization framework is implemented as a modular Python system with separate modules for each algorithm located in \texttt{scripts/optimization/}. A unified runner interface (\texttt{optimization\_runner.py}) provides consistent access to all methods through a common API. The command-line interface supports batch processing, method comparison, and continuation of interrupted runs. All results are logged with timestamps and saved in CSV format for reproducibility.

\subsection{Performance Comparison}

Table~1 presents a systematic comparison of all six optimization methods applied to representative lens pairs. Each method was evaluated on computational time, coupling efficiency achieved, and total system length. All results include atmospheric absorption at 200 nm.

\begin{table}[h]
\centering
\caption{Optimization Algorithm Performance Comparison (with atmospheric absorption)}
\small
\begin{tabular}{lccc}
\hline
\textbf{Method} & \textbf{Time (s)} & \textbf{$\bm{\eta}$} & \textbf{$\bm{L}$ (mm)} \\
\hline
Grid Search & 1.6--45 & 0.223 & 63.9 \\
Powell & 0.8--1.3 & 0.197 & 33.0 \\
Nelder-Mead & 0.4--2.0 & 0.242 & 32.9 \\
Diff. Evol. & 0.8--1.7 & 0.230 & 32.9 \\
Dual Anneal. & 1.0--5.1 & 0.222 & 34.4 \\
Bayesian & 2.0--3.5 & 0.218 & 33.1 \\
\hline
\end{tabular}
\end{table}

\textbf{Key findings:}

\begin{itemize}[leftmargin=*]
    \item \textit{Differential evolution} provides the best balance: comparable or superior coupling to grid search with 10--56$\times$ speedup (0.8--1.7~s vs 45~s per lens pair).
    
    \item \textit{Local methods} (Powell, Nelder-Mead) converge fastest (0.4--2.0~s) but are sensitive to initialization. Nelder-Mead achieved the highest observed coupling (0.242) when properly initialized.
    
    \item \textit{Grid search} serves as a reliable baseline, exhaustively sampling 130 configurations. However, computational cost scales poorly for finer resolution or higher-dimensional searches.
    
    \item \textit{Dual annealing} explores the parameter space thoroughly, occasionally finding solutions competitive with differential evolution, at moderate computational cost.
    
    \item \textit{Bayesian optimization} demonstrates sample efficiency but requires the additional \texttt{scikit-optimize} dependency. Best suited when function evaluations are extremely expensive.
    
    \item \textit{Atmospheric absorption} reduces coupling by $\sim$11\% compared to earlier vacuum-propagation models (previous best: 0.273 $\rightarrow$ current best: 0.242).
\end{itemize}

\subsection{Multi-Objective Optimization Results}

The weighted objective function with tunable parameter $\alpha$ enables exploration of the coupling-compactness trade-off. Figure~2 (not shown) illustrates the Pareto frontier for selected lens pairs.

For the lens combination 36-681 + LA4647 (with atmospheric absorption):
\begin{itemize}[leftmargin=*]
    \item $\alpha = 0.9$ (coupling priority): $\eta = 0.2416$, $L = 32.9$~mm
    \item $\alpha = 0.7$ (balanced, default): $\eta = 0.2298$, $L = 32.9$~mm  
    \item $\alpha = 0.5$ (equal weight): $\eta = 0.222$, $L = 32.5$~mm
\end{itemize}

The relatively flat trade-off curve indicates that for this particular lens pair, compact configurations ($L \approx 33$~mm) can be achieved without significant coupling degradation. Other lens combinations exhibit steeper trade-offs, requiring $\alpha$ adjustment based on application constraints.

\subsection{Lens Selection Analysis}

Analysis of high-performing configurations ($\eta > 0.20$) across 925+ lens pair evaluations with atmospheric absorption reveals:

\begin{itemize}[leftmargin=*]
    \item \textit{Best overall coupling}: 36-681 + LA4647 achieved $\eta = 0.2416$ with $L = 32.9$~mm (optimized compact design with excellent coupling)
    
    \item \textit{Long system performance}: 36-682 + LA4021 achieved $\eta = 0.2188$ with $L = 94.7$~mm (high NA matching, longer focal lengths)
    
    \item \textit{Focal length ratio}: Pairs with $f_2/f_1 \approx 0.9$--1.2 generally outperform extreme ratios, suggesting relay magnification near unity is favorable
    
    \item \textit{First lens position}: Optimal $z_1$ typically ranges 9.7--12~mm (just beyond the protective window), allowing sufficient beam expansion before the first lens
    
    \item \textit{Absorption impact}: Atmospheric O$_2$ absorption at 200 nm reduces coupling by approximately 11\% compared to vacuum propagation (0.273 $\rightarrow$ 0.242 for best case)
\end{itemize}

\subsection{Propagation Medium Effects}

A systematic comparison of air versus argon propagation was conducted to evaluate whether inert gas purging provides performance benefits. At 200 nm, argon exhibits negligible VUV absorption compared to O$_2$-containing air, which might suggest improved coupling efficiency in argon-filled systems.

However, analysis of five representative lens pairs optimized separately in air and argon environments reveals:

\begin{itemize}[leftmargin=*]
    \item \textit{Coupling difference}: $\Delta\eta < 0.003$ (0.3\%) between air and argon across all tested configurations
    \item \textit{System geometry}: Optimal lens positions ($z_1$, $z_2$) differ by less than 0.2 mm between media
    \item \textit{Refractive index}: Both air ($n \approx 1.0003$) and argon ($n \approx 1.0003$) at 200 nm are negligibly different from vacuum
\end{itemize}

The near-zero coupling difference arises because the dominant optical path ($\sim$80--90\% of total system length) is through fused silica lenses ($n = 1.578$), not the inter-lens medium. While air absorption attenuates the beam by $\sim$11\% compared to vacuum, this loss occurs primarily in the long pre-lens and post-lens propagation distances where the medium choice is dictated by the lamp housing and experimental setup.

\textbf{Conclusion:} For practical two-lens systems in this geometry, air is an acceptable working medium without need for argon purging, greatly simplifying experimental implementation.

\subsection{Computational Efficiency}

For a complete lens catalog scan (925 combinations):
\begin{itemize}[leftmargin=*]
    \item Grid search: $\sim$12 hours (45 s/pair $\times$ 925)
    \item Differential evolution: $\sim$20 minutes (1.3 s/pair $\times$ 925)
    \item \textbf{Speedup: 36$\times$} for full catalog optimization
\end{itemize}

The modular architecture enables parallel batch processing, further reducing wall-clock time on multi-core systems.

\section{Conclusions}

A comprehensive computational framework has been developed for designing two-lens VUV coupling systems based on Monte Carlo ray tracing and multi-algorithm optimization. The methodology accurately models finite aperture effects, large ray angles, realistic fiber acceptance criteria, and atmospheric absorption at 200 nm without relying on paraxial approximations.

Systematic comparison of six optimization algorithms reveals that \textbf{differential evolution} provides the optimal balance of solution quality, computational efficiency, and robustness. Achieving 10--56$\times$ speedup over grid search while finding superior or equivalent solutions, it is recommended as the default method for optical coupling design problems of this type.

Local optimization methods (Powell, Nelder-Mead) offer rapid convergence when initialized near global optima, making them suitable for design refinement. Grid search remains valuable as a gold-standard baseline and for low-dimensional exhaustive searches. Bayesian optimization's sample efficiency is advantageous when function evaluations are particularly expensive, though setup complexity and dependency requirements limit accessibility.

The multi-objective framework successfully navigates the coupling-compactness trade-off through the tunable $\alpha$ parameter. Analysis of 925+ lens pair configurations identifies key design principles: focal length ratios near unity, first lens positioning 9.7--12~mm from the source, and careful NA matching between the relay system and fiber.

\textbf{Atmospheric absorption at 200 nm}, modeled using the Minschwaner O$_2$ cross-section parameterization, causes approximately 11\% coupling reduction compared to vacuum propagation. This represents a significant but manageable loss mechanism. Comparison of air and argon propagation media shows negligible performance difference ($\Delta\eta < 0.3\%$), validating air as a practical working environment and eliminating the need for inert gas purging in experimental setups.

Achieved coupling efficiencies of 0.19--0.24 in air represent realistic predictions for laboratory systems. The best compact design (36-681 + LA4647) achieves $\eta = 0.242$ with total length $L = 32.9$ mm. Experimental realization will require additional consideration of: (1) Fresnel reflection losses ($\sim$5\% per surface, $\sim$20\% total for 4 surfaces), (2) bulk absorption in UV optics, (3) alignment tolerances, and (4) actual arc lamp spatial and angular emission distributions. Incorporating Fresnel losses would reduce the predicted coupling to approximately 0.19--0.20, setting realistic experimental targets.

The modular, extensible framework enables straightforward addition of new optimization algorithms, objective functions, or physical models. The absorption model is implemented in \texttt{scripts/calcs.py} and \texttt{scripts/hitran\_data.py} using empirical cross-section parameterizations. Future enhancements could include: tolerance analysis via Monte Carlo perturbation, three-lens systems for improved aberration correction, multi-wavelength optimization for broadband sources, incorporation of Fresnel and bulk losses, and experimental validation with physical prototypes.

This work provides both a practical design tool for VUV fiber coupling applications and methodological insights applicable to non-convex optical design optimization problems with expensive black-box objective functions.


\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
